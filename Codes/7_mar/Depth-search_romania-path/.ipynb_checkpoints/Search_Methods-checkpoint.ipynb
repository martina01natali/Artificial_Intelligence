{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uninformed Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents functions to perform different types of uninformed search methods: breadth first, depth first, limited depth search, iterative deepening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Oradea': {'Zerind': 71, 'Sibiu': 151}, 'Zerind': {'Oradea': 71, 'Arad': 75}, 'Sibiu': {'Oradea': 151, 'Arad': 140, 'Rimnicu Vilcea': 80, 'Fagaras': 99}, 'Arad': {'Zerind': 75, 'Sibiu': 140, 'Timisoara': 118}, 'Timisoara': {'Arad': 118, 'Lugoj': 111}, 'Lugoj': {'Timisoara': 111, 'Mehadia': 70}, 'Mehadia': {'Lugoj': 70, 'Dobreta': 75}, 'Dobreta': {'Mehadia': 75, 'Craiova': 120}, 'Craiova': {'Dobreta': 120, 'Rimnicu Vilcea': 146, 'Pitesti': 138}, 'Rimnicu Vilcea': {'Sibiu': 80, 'Pitesti': 97, 'Craiova': 146}, 'Fagaras': {'Sibiu': 99, 'Bucharest': 211}, 'Pitesti': {'Rimnicu Vilcea': 97, 'Craiova': 138, 'Bucharest': 101}, 'Bucharest': {'Pitesti': 101, 'Fagaras': 211, 'Giurgiu': 90, 'Urziceni': 85}, 'Giurgiu': {'Bucharest': 90}, 'Urziceni': {'Bucharest': 85, 'Hirsova': 98, 'Vaslui': 142}, 'Hirsova': {'Urziceni': 98, 'Eforie': 86}, 'Vaslui': {'Urziceni': 142, 'Iasi': 92}, 'Eforie': {'Hirsova': 86}, 'Iasi': {'Vaslui': 92, 'Neamt': 87}, 'Neamt': {'Iasi': 87}}\n"
     ]
    }
   ],
   "source": [
    "# Preparing data to work on\n",
    "# Data are a list of couples of cities and their distance\n",
    "\n",
    "dict_graph = {}\n",
    "\n",
    "with open('data.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        city_a, city_b, p_cost = line.split(\",\")\n",
    "        if city_a not in dict_graph:\n",
    "            dict_graph[city_a] = {}\n",
    "        dict_graph[city_a][city_b] = int(p_cost)\n",
    "        if city_b not in dict_graph:\n",
    "            dict_graph[city_b] = {}\n",
    "        dict_graph[city_b][city_a] = int(p_cost)\n",
    "\n",
    "print(dict_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breadth First Search Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am exploring the tree \"horizontally\", expanding all nodes at the same depth before moving deeper.\n",
    "I must initialize an empty queue and an array/dict of visited nodes.\n",
    "\n",
    "I take the first node and I put it in the queue, then I expand it and see if it is the goal. If not, we add it to the \"visited\" list. And then I go on and move from one node to another by following the connections that I know between them. Bear in mind that the nodes are generated when I get to a neighbor but they are not visited immediately.\n",
    "\n",
    "The purpose of the visited list is to prevent us from going to the same place twice.\n",
    "\n",
    "The difference between breadth first and depth first is that in the first we are taking the _head_ of the queue (.pop(0)) and then adding to the visited, whilst in the latter we are taking from the _end_ of the queue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BreadthFirstSearch(graph:dict, src:str, dst:str):\n",
    "    \"\"\"Function to perform BFS.\n",
    "    Inputs\n",
    "    ------\n",
    "    - graph: dict whose keys are nodes of the graph and values are annidated dicts with all possible successors of given key as keys and distance wrt main key node as values\n",
    "    - src: source/root node (initial key)\n",
    "    - dst: destination (goal key)    \n",
    "    \"\"\"\n",
    "    # q = queue is a list of tuples of three elements that is initiated with name and info of src node\n",
    "    q = [(src, [src], 0)]\n",
    "    # visited is a set, so a collection of unique values, to which values can be add via .add(values)\n",
    "    visited = {src}\n",
    "    while q:\n",
    "        (node, path, cost) = q.pop(0) # take the FIRST ELEMENT OF THE QUEUE\n",
    "        for temp in graph[node].keys(): # loop on its successor nodes\n",
    "            if temp == dst: # check if it is the goal\n",
    "                print(' --> '.join(path),' --> ',temp)\n",
    "                    # 'del'.join(sequence) is used to sum a sequence of strings with a delimiter del\n",
    "                return True\n",
    "            else: \n",
    "                if temp not in visited:\n",
    "                    print(' --> '.join(path),' --> ',temp)\n",
    "                    visited.add(temp)\n",
    "                    q.append((temp, path + [temp], cost + graph[node][temp])) # appends to the END of the queue the tuples of the successors of the source node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth First Search Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goes down a single branch until it reaches its end and then moves to another one. Before moving on to the next branch, it clears its memory completely to avoid using a lot of space.\n",
    "\n",
    "The algorithm is almost equal to the one for BFS but taking the last element of the queue instead of the first makes you go down the branch instead of expanding nodes at the same depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DepthFirstSearch(graph, src, dst):\n",
    "    stack = [(src, [src], 0)] # this is the queue\n",
    "    visited = {src} # this is the set of visited nodes\n",
    "    while stack:\n",
    "        (node, path, cost) = stack.pop() # takes the LAST ELEMENT OF THE QUEUE\n",
    "        for temp in graph[node].keys():\n",
    "            if temp == dst:\n",
    "                print(' --> '.join(path),' --> ',temp)\n",
    "                return True\n",
    "            else:\n",
    "                if temp not in visited:\n",
    "                    visited.add(temp)                    \n",
    "                    print(' --> '.join(path),' --> ',temp)\n",
    "                    stack.append((temp, path + [temp], cost + graph[node][temp]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limited Depth Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depth first approach with a limit on the maximum depth allowed to go, provided by `level`. The limit on the depth is fixed when appending the successors to the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LimitedDepthSearch(graph, src, dst, level):\n",
    "    stack = [(src, [src], 0)]\n",
    "    visited = {src}\n",
    "    \n",
    "    while stack:\n",
    "        (node, path, cost) = stack.pop()\n",
    "        for temp in graph[node].keys(): #read what is connected to node\n",
    "            if temp == dst:\n",
    "                print(' --> '.join(path),' --> ',temp)\n",
    "                return True\n",
    "            else:\n",
    "                if temp not in visited:\n",
    "                    visited.add(temp)\n",
    "                    print(' --> '.join(path),' --> ',temp)\n",
    "                    if len(path)<level:\n",
    "                        stack.append((temp, path + [temp], cost + graph[node][temp]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Deepening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a depth limited search and make it iterative by incrementing maximum depth at each iteration. At every iteration the memory is cleared at the beginning and the search is performed from scratch (from depth 0 to the maximum depth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IterativeDeepening(graph, src, dst):\n",
    "    stack = [(src, [src], 0)]\n",
    "    visited = {src}\n",
    "    level=0\n",
    "    control=1\n",
    "    while control==1:\n",
    "        stack = [(src, [src], 0)]\n",
    "        visited = {src}\n",
    "        level+=1\n",
    "        print('DEPTH: ',level)\n",
    "        while stack:\n",
    "            (node, path, cost) = stack.pop()\n",
    "            for temp in graph[node].keys(): #read what is connected to node\n",
    "                if temp == dst:\n",
    "                    control=0\n",
    "                    print(' --> '.join(path),' --> ',temp)\n",
    "                    return True\n",
    "                else:\n",
    "                    if temp not in visited:\n",
    "                        visited.add(temp)\n",
    "                        print(' --> '.join(path),' --> ',temp)\n",
    "                        if len(path)<level:\n",
    "                            stack.append((temp, path + [temp], cost + graph[node][temp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oradea  :  {'Zerind': 71, 'Sibiu': 151}\n",
      "Zerind  :  {'Oradea': 71, 'Arad': 75}\n",
      "Sibiu  :  {'Oradea': 151, 'Arad': 140, 'Rimnicu Vilcea': 80, 'Fagaras': 99}\n",
      "Arad  :  {'Zerind': 75, 'Sibiu': 140, 'Timisoara': 118}\n",
      "Timisoara  :  {'Arad': 118, 'Lugoj': 111}\n",
      "Lugoj  :  {'Timisoara': 111, 'Mehadia': 70}\n",
      "Mehadia  :  {'Lugoj': 70, 'Dobreta': 75}\n",
      "Dobreta  :  {'Mehadia': 75, 'Craiova': 120}\n",
      "Craiova  :  {'Dobreta': 120, 'Rimnicu Vilcea': 146, 'Pitesti': 138}\n",
      "Rimnicu Vilcea  :  {'Sibiu': 80, 'Pitesti': 97, 'Craiova': 146}\n",
      "Fagaras  :  {'Sibiu': 99, 'Bucharest': 211}\n",
      "Pitesti  :  {'Rimnicu Vilcea': 97, 'Craiova': 138, 'Bucharest': 101}\n",
      "Bucharest  :  {'Pitesti': 101, 'Fagaras': 211, 'Giurgiu': 90, 'Urziceni': 85}\n",
      "Giurgiu  :  {'Bucharest': 90}\n",
      "Urziceni  :  {'Bucharest': 85, 'Hirsova': 98, 'Vaslui': 142}\n",
      "Hirsova  :  {'Urziceni': 98, 'Eforie': 86}\n",
      "Vaslui  :  {'Urziceni': 142, 'Iasi': 92}\n",
      "Eforie  :  {'Hirsova': 86}\n",
      "Iasi  :  {'Vaslui': 92, 'Neamt': 87}\n",
      "Neamt  :  {'Iasi': 87}\n"
     ]
    }
   ],
   "source": [
    "for key, value in dict_graph.items():\n",
    "    print(key, ' : ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number corresponding to the type of search you want to do \n",
      "1.Breadth First Search \n",
      "2.Depth First Search \n",
      "3.Limited Depth Search \n",
      "4.Iterative Deepening:: \n",
      "  1\n",
      "Enter the source:  Oradea\n",
      "Enter the Destination:  Neamt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for BFS\n",
      "<class 'set'>\n",
      "Oradea  -->  Zerind\n",
      "Oradea  -->  Sibiu\n",
      "Oradea --> Zerind  -->  Arad\n",
      "Oradea --> Sibiu  -->  Rimnicu Vilcea\n",
      "Oradea --> Sibiu  -->  Fagaras\n",
      "Oradea --> Zerind --> Arad  -->  Timisoara\n",
      "Oradea --> Sibiu --> Rimnicu Vilcea  -->  Pitesti\n",
      "Oradea --> Sibiu --> Rimnicu Vilcea  -->  Craiova\n",
      "Oradea --> Sibiu --> Fagaras  -->  Bucharest\n",
      "Oradea --> Zerind --> Arad --> Timisoara  -->  Lugoj\n",
      "Oradea --> Sibiu --> Rimnicu Vilcea --> Craiova  -->  Dobreta\n",
      "Oradea --> Sibiu --> Fagaras --> Bucharest  -->  Giurgiu\n",
      "Oradea --> Sibiu --> Fagaras --> Bucharest  -->  Urziceni\n",
      "Oradea --> Zerind --> Arad --> Timisoara --> Lugoj  -->  Mehadia\n",
      "Oradea --> Sibiu --> Fagaras --> Bucharest --> Urziceni  -->  Hirsova\n",
      "Oradea --> Sibiu --> Fagaras --> Bucharest --> Urziceni  -->  Vaslui\n",
      "Oradea --> Sibiu --> Fagaras --> Bucharest --> Urziceni --> Hirsova  -->  Eforie\n",
      "Oradea --> Sibiu --> Fagaras --> Bucharest --> Urziceni --> Vaslui  -->  Iasi\n",
      "Oradea --> Sibiu --> Fagaras --> Bucharest --> Urziceni --> Vaslui --> Iasi  -->  Neamt\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "\n",
    "#for key, value in dict_graph.items():\n",
    "#    print(key, ' : ', value)\n",
    "Image(filename='romania.png')     \n",
    "\n",
    "print (\"------------------------------------------------\")\n",
    "x = int(input(\"Enter the number corresponding to the type of search you want to do \\n1.Breadth First Search \\n2.Depth First Search \\n3.Limited Depth Search \\n4.Iterative Deepening:: \\n \"))\n",
    "if x == 1:\n",
    "    src = input(\"Enter the source: \")\n",
    "    dst = input(\"Enter the Destination: \")\n",
    "    while src not in dict_graph or dst not in dict_graph:\n",
    "        print (\"No such city name\")\n",
    "        src = input(\"Enter the correct source (case_sensitive):\\n\")\n",
    "        dst = input(\"Enter the correct destination(case_sensitive):\\n \")\n",
    "    print (\"for BFS\")\n",
    "    print (BreadthFirstSearch(dict_graph, src, dst))\n",
    "        \n",
    "elif x == 2:\n",
    "    src = input(\"Enter the source: \")\n",
    "    dst = input(\"Enter the Destination: \")\n",
    "    while src not in dict_graph or dst not in dict_graph:\n",
    "        print (\"No such city name\")\n",
    "        src = input(\"Enter the correct source (case_sensitive):\\n\")\n",
    "        dst = input(\"Enter the correct destination(case_sensitive):\\n \")\n",
    "    print (\"for DFS\")\n",
    "    print (DepthFirstSearch(dict_graph, src, dst))\n",
    "        \n",
    "elif x == 3:\n",
    "    src = input(\"Enter the source: \")\n",
    "    dst = input(\"Enter the Destination: \")\n",
    "    level = int(input(\"Enter the Depth: \"))\n",
    "    while src not in dict_graph or dst not in dict_graph:\n",
    "        print (\"No such city name\")\n",
    "        src = input(\"Enter the correct source (case_sensitive):\\n\")\n",
    "        dst = input(\"Enter the correct destination(case_sensitive):\\n \")\n",
    "    print (\"for LDS\")\n",
    "    print (LimitedDepthSearch(dict_graph, src, dst,level))\n",
    "        \n",
    "elif x == 4:\n",
    "    src = input(\"Enter the source:\")\n",
    "    dst = input(\"Enter the Destination: \")\n",
    "    while src not in dict_graph or dst not in dict_graph:\n",
    "        print (\"No such city name\")\n",
    "        src = input(\"Enter the correct source (case_sensitive):\\n\")\n",
    "        dst = input(\"Enter the correct destination(case_sensitive):\\n\")\n",
    "    print (\"for ID\")\n",
    "    print (IterativeDeepening(dict_graph, src, dst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"romania.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
